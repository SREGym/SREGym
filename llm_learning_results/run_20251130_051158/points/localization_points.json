[
  {
    "id": "c07a0876-ef6b-4d45-b838-a6f1d99896b9",
    "content": "## Structured Fault Localization Strategy\nFollow an iterative observation-hypothesis-test cycle:\n1.  **Observe:** Use general `kubectl get` and `kubectl describe` commands (e.g., `get pods`, `get deployments`, `describe pod <pod-name>`) to understand the initial state and identify any obvious issues (e.g., CrashLoopBackOff, Pending pods, high restarts).\n2.  **Hypothesize:** Based on your observations, form a hypothesis about the potential fault location (e.g., 'The pod is failing due to a misconfiguration', 'Network traffic is blocked').\n3.  **Test:** Use specific tools and commands to validate or invalidate your hypothesis. For example, if you suspect a network issue, check `NetworkPolicy` or `Service` configurations. If you suspect resource contention, check `pod` resource limits and usage metrics.\n4.  **Refine & Localize:** If your hypothesis is disproven, refine it or form a new one and repeat the testing. Once a hypothesis is confirmed and the root cause identified, proceed to submission.",
    "source": "learned",
    "category": "tool_usage",
    "priority": 6,
    "verified": false,
    "verification_count": 0,
    "success_count": 0,
    "failure_count": 0,
    "conflicts_with": [],
    "replaces": null,
    "replaced_by": null,
    "active": true,
    "created_at": "2025-11-30T05:08:22.880616",
    "last_updated": "2025-11-30T05:08:22.880619",
    "metadata": {}
  },
  {
    "id": "ae954b7a-1933-44d2-8bd9-c26db3b92fe5",
    "content": "## Resource Contention and Limits Troubleshooting\nIf performance degradation (e.g., high CPU, high memory usage, or unexpected restarts like OOMKills) is observed or suspected, prioritize checking the resource requests and limits defined for the affected pods. Use `kubectl describe pod <pod-name> -n <namespace>` to inspect the `Limits` and `Requests` sections. This can quickly reveal if the application is being throttled or starved of resources, as seen in `astronomy_shop_ad_service_high_cpu` and `valkey_memory_disruption` failures. Address resource misconfigurations before delving into application-specific metrics.",
    "source": "learned",
    "category": "tool_usage",
    "priority": 6,
    "verified": false,
    "verification_count": 0,
    "success_count": 0,
    "failure_count": 0,
    "conflicts_with": [],
    "replaces": null,
    "replaced_by": null,
    "active": true,
    "created_at": "2025-11-30T06:02:21.061061",
    "last_updated": "2025-11-30T06:02:21.061064",
    "metadata": {}
  },
  {
    "id": "ea2bc856-513c-44ca-ba0e-5e342eafc8aa",
    "content": "## Systematic Configuration, Authorization, and Storage Review\nWhen application misbehavior, denied access, or data persistence issues are identified (e.g., `misconfig_app_hotel_res`, `revoke_auth_mongodb-1`, `duplicate_pvc_mounts_hotel_reservation`), systematically review relevant configuration, authorization, and storage resources:\n- **Application Configuration:** Inspect `ConfigMap` and `Secret` resources linked to the failing pods/deployments. Use `kubectl get configmap <name> -o yaml` and `kubectl get secret <name> -o yaml` (be cautious with secret content, focus on names and keys).\n- **Authorization Failures:** For permission-related errors, examine `ServiceAccount`s used by pods, along with `Role`s, `RoleBinding`s, `ClusterRole`s, and `ClusterRoleBinding`s. Start by checking the `serviceAccountName` in the pod definition.\n- **Storage Issues:** For data access or persistence problems, investigate `PersistentVolumeClaim` (PVC) and `PersistentVolume` (PV) resources associated with the application. Verify their status, correct mounting in pod definitions, and associated `StorageClass`.",
    "source": "learned",
    "category": "tool_usage",
    "priority": 6,
    "verified": false,
    "verification_count": 0,
    "success_count": 0,
    "failure_count": 0,
    "conflicts_with": [],
    "replaces": null,
    "replaced_by": null,
    "active": true,
    "created_at": "2025-11-30T06:02:21.061596",
    "last_updated": "2025-11-30T06:02:21.061599",
    "metadata": {}
  }
]