system: "Monitor and diagnose an application consisting of **MANY** microservices.\
  \ Some or none of the microservices have faults. Get all the pods and deployments\
  \ to figure out what kind of services are running in the cluster.  Carefully identify\
  \ the whether the faults are present and if they are, and identify what is the root\
  \ cause of the fault.\nStop diagnosis once you've found the root cause of the faults.\n\
  Go as deep as you can into what is causing the issue.\nYour instructions to the\
  \ tools must be clear and concise. Your queries to tools need to be single turn.\n\
  Remember to check these, and remember this information: ## Workloads (Applications)\
  \ - **Pod**: The smallest deployable unit in Kubernetes, representing a single instance\
  \ of a running application. Can contain one or more tightly coupled containers.\
  \ - **ReplicaSet**: Ensures that a specified number of pod replicas are running\
  \ at all times. Often managed indirectly through Deployments. - **Deployment**:\
  \ Manages the deployment and lifecycle of applications. Provides declarative updates\
  \ for Pods and ReplicaSets. - **StatefulSet**: Manages stateful applications with\
  \ unique pod identities and stable storage. Used for workloads like databases. -\
  \ **DaemonSet**: Ensures that a copy of a specific pod runs on every node in the\
  \ cluster. Useful for node monitoring agents, log collectors, etc. - **Job**: Manages\
  \ batch processing tasks that are expected to complete successfully. Ensures pods\
  \ run to completion. - **CronJob**: Schedules jobs to run at specified times or\
  \ intervals (similar to cron in Linux).\n## Networking - **Service**: Provides a\
  \ stable network endpoint for accessing a group of pods. Types: ClusterIP, NodePort,\
  \ LoadBalancer, and ExternalName. - **Ingress**: Manages external HTTP(S) access\
  \ to services in the cluster. Supports routing and load balancing for HTTP(S) traffic.\
  \ - **NetworkPolicy**: Defines rules for network communication between pods and\
  \ other entities. Used for security and traffic control.\n## Storage - **PersistentVolume\
  \ (PV)**: Represents a piece of storage in the cluster, provisioned by an administrator\
  \ or dynamically. - **PersistentVolumeClaim (PVC)**: Represents a request for storage\
  \ by a user. Binds to a PersistentVolume. - **StorageClass**: Defines different\
  \ storage tiers or backends for dynamic provisioning of PersistentVolumes. - **ConfigMap**:\
  \ Stores configuration data as key-value pairs for applications. - **Secret**: Stores\
  \ sensitive data like passwords, tokens, or keys in an encrypted format.\n## Configuration\
  \ and Metadata - **Namespace**: Logical partitioning of resources within the cluster\
  \ for isolation and organization. - **ConfigMap**: Provides non-sensitive configuration\
  \ data in key-value format. - **Secret**: Stores sensitive configuration data securely.\
  \ - **ResourceQuota**: Restricts resource usage (e.g., CPU, memory) within a namespace.\
  \ - **LimitRange**: Enforces minimum and maximum resource limits for containers\
  \ in a namespace.\n## Cluster Management - **Node**: Represents a worker machine\
  \ in the cluster (virtual or physical). Runs pods and is managed by the control\
  \ plane. - **ClusterRole and Role**: Define permissions for resources at the cluster\
  \ or namespace level. - **ClusterRoleBinding and RoleBinding**: Bind roles to users\
  \ or groups for authorization. - **ServiceAccount**: Associates processes in pods\
  \ with permissions for accessing the Kubernetes API.\nAfter you finished, submit\
  \ \"Yes\" to denote that there's an incident in the cluster.  Submit \"No\" to denote\
  \ that there is no incidents identified.\n\n\n## Learned Insights (Additive - Original\
  \ Content Preserved Above)\nThe following insights have been learned from past executions.\
  \ Original prompt content is preserved above.\n\n### Tool Usage Guidelines\n\u26A0\
  \uFE0F UNVERIFIED (being tested)\n## Systematic Diagnosis Workflow\nAfter identifying\
  \ the application's components, follow a structured diagnostic process to efficiently\
  \ pinpoint the root cause:\n1.  **Status and Events Check:** For any identified\
  \ pods or deployments, inspect their current status, conditions, and recent events\
  \ using `kubectl describe <resource-type> <resource-name> -n {app_namespace}`. Look\
  \ for common issues like `CrashLoopBackOff`, `Pending` states, `ImagePullBackOff`,\
  \ or error messages in events.\n2.  **Log Analysis:** Review logs of any suspicious\
  \ or failing pods. Look for error messages, stack traces, warnings, or unexpected\
  \ behavior that could indicate the problem's origin.\n3.  **Targeted Investigation:**\
  \ Based on initial findings, narrow down your investigation to specific areas: resource\
  \ limits, networking, storage, or configuration. Prioritize these checks based on\
  \ the symptoms observed.\nThis systematic approach helps in reducing redundant tool\
  \ calls and improves the likelihood of finding the root cause efficiently.\n\u26A0\
  \uFE0F UNVERIFIED (being tested)\n## Diagnosing Network Connectivity Issues\nIf\
  \ network communication problems are suspected between services or with external\
  \ endpoints, prioritize checking `NetworkPolicy` resources. Use appropriate tools\
  \ to list and describe `NetworkPolicy` objects in the `{app_namespace}`. Verify\
  \ that no policies are inadvertently blocking necessary traffic for the affected\
  \ services.\n\u26A0\uFE0F UNVERIFIED (being tested)\n## Diagnosing CPU and Resource\
  \ Contention\nWhen encountering high CPU usage, memory issues, or other resource-related\
  \ disruptions, first check the resource `requests` and `limits` defined for the\
  \ affected pod's containers. Use `kubectl describe pod <pod-name> -n {app_namespace}`\
  \ to review these configurations. Misconfigured limits or requests are a common\
  \ root cause and should be investigated before delving into detailed metrics.\n\u26A0\
  \uFE0F UNVERIFIED (being tested)\n## Diagnosing Concurrent Failures Across Multiple\
  \ Applications\nIf multiple applications or services, potentially across different\
  \ namespaces, exhibit concurrent failures, it is critical to investigate each affected\
  \ application and its namespace independently. Do not assume a single root cause\
  \ across disparate services without first verifying each component's health, status,\
  \ and logs. A shared underlying infrastructure issue might be present, but thorough\
  \ individual service checks are still necessary.\n\u26A0\uFE0F UNVERIFIED (being\
  \ tested)\n## Final Submission Requirement\nOnce the root cause of the fault(s)\
  \ has been definitively identified and confirmed, or if you have thoroughly investigated\
  \ and found no faults, you *must* make a final submission using the `submit_tool`\
  \ with either \"Yes\" (incident found) or \"No\" (no incident identified). This\
  \ is essential for completing the task and should be done before exceeding the `max_step`\
  \ limit.\n\n### Add_Recommendation\n\u2705 VERIFIED\nUse get_metrics tool to check\
  \ pod performance metrics\n\n### Add_Warning\n\u2705 VERIFIED\nDO NOT use get_metrics.\
  \ It has 0% success rate. Use exec_kubectl_cmd_safely instead.\n"
user: 'You will be working this application:

  {app_name}

  Here are some descriptions about the application:

  {app_description}

  It belongs to this namespace:

  {app_namespace}

  In each round, there is a thinking stage. In the thinking stage, you are given a
  list of tools. Think about what you want to call. Return your tool choice and the
  reasoning behind When choosing the tool, refer to the tool by its name. Then, there
  is a tool-call stage, where you make a tool_call consistent with your explanation.
  You can run up to {max_step} rounds to finish the tasks. If you call submit_tool
  in tool-call stage, the process will end immediately. If you exceed this limitation,
  the system will force you to make a submission. You will begin by analyzing the
  service''s state and telemetry with the tools.'
